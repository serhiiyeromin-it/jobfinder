# ğŸ› ï¸ Night Crawler â€“ Backend

Flaskâ€‘API mit MongoDBâ€‘Anbindung, Crawlerâ€‘Logik (z.â€¯B. BAAâ€‘API), APScheduler und optionaler Eâ€‘Mailâ€‘Benachrichtigung.

## Voraussetzungen

- Python **3.11**
- MongoDB (lokal/remote)
- `pip`, virtuelle Umgebung empfohlen

## Installation & Start (Lokal)

```bash
cd backend
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

export MONGO_URI="mongodb://localhost:27017/nightcrawler"
export BAA_API_KEY="jobboerse-jobsuche"

# optional fÃ¼r Eâ€‘Mail
export MAIL_SERVER="smtp.example.com"
export MAIL_PORT="587"
export MAIL_USERNAME="example@example.com"
export MAIL_PASSWORD="supersecret"

python server.py
# â†’ http://127.0.0.1:5000
```

## Wichtige Dateien

- `server.py` â€“ Flaskâ€‘App, Routen, Scheduling, Eâ€‘Mail
- `crawler_api_baa.py` â€“ Anbindung an BAAâ€‘API
- `mongodb_connect.py` â€“ Mongoâ€‘Connection und Collections
- `requirements.txt` â€“ Pythonâ€‘Dependencies
- `tests/` â€“ Pytestâ€‘Suiten (u.â€¯a. Verbindungsâ€‘ und CRUDâ€‘Tests)

## API (Auszug)

- `GET /health` â€“ Healthcheck
- `GET|POST /jobsuchen` â€“ allgemeine Suche
- `POST /jobsuchen_baa` â€“ BAAâ€‘Suche
- `GET /bookmarked_jobs` â€“ Bookmarks abrufen
- `POST /update_bookmark` â€“ Bookmark anlegen/Ã¤ndern
- `POST /save_search` â€“ Alert speichern
- `GET /search_alerts` â€“ Alerts anzeigen
- `POST /update_search_alert/<id>` â€“ Alert aktualisieren
- `DELETE /delete_search_alert/<id>` â€“ Alert lÃ¶schen
- `GET /get_search_results/<alert_id>` â€“ Ergebnisse zu einem Alert

## Tests

```bash
pytest --cov=backend --cov-report=term-missing
```

## Docker

Das Backendâ€‘Image ist als `mrrobob/nightcrawler-backend` verfÃ¼gbar und wird von CI gebaut.
Im Compose ist der Service unter Port **3050** erreichbar.

## Tipps

- Indizes auf Collections prÃ¼fen (Duplikatvermeidung)
- Logging aktivieren (Requests/Antworten, Crawlingâ€‘Jobs)
- `.env` via `python-dotenv` laden, sensibel mit Secrets umgehen
